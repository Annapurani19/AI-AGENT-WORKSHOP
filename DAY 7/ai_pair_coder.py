# -*- coding: utf-8 -*-
"""AI PAIR CODER.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1M2pJfR52yOL2sRSAWypsakmwtMrf0yxQ
"""

!pip install -U langchain langchain_community langchain_google_genai google-generativeai gradio faiss-cpu chromadb tiktoken

import os
import gradio as gr
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.agents import AgentExecutor, create_tool_calling_agent
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.tools import Tool
from langchain.memory import ConversationBufferMemory

# 🔑 SET YOUR GOOGLE API KEY (from https://makersuite.google.com/app/apikey)
os.environ["GOOGLE_API_KEY"] = "AIzaSyBrJq2pA3RaiXHkSDIzx6JZsrtkK0skbts"  # 🔁 Replace with your real key

# Gemini 1.5 Flash Model
llm = ChatGoogleGenerativeAI(model="gemini-1.5-flash", temperature=0.4)

# ========= TOOLS ==========

def select_persona(preference: str) -> str:
    """Selects a learning persona style."""
    options = {
        "Strict Mentor": "High challenge, minimal hints.",
        "Chill Peer": "Relaxed help, medium hints.",
        "Cheerleader": "Encouraging support with detailed hints."
    }
    return options.get(preference, "Please choose: Strict Mentor, Chill Peer, or Cheerleader.")

def interactive_coding(task: str, persona: str) -> str:
    """Provides code help in selected persona's style."""
    if persona == "Strict Mentor":
        return f"Here’s your task: {task}. Solve it without help."
    elif persona == "Chill Peer":
        return f"Let's solve this together: {task}. Ask if needed!"
    elif persona == "Cheerleader":
        return f"You're amazing! Let's do this: {task}. Hint 👉 break it down!"
    else:
        return "Unrecognized persona."

def feedback(score: int, errors: int, time_minutes: int) -> str:
    """Gives feedback based on user performance."""
    if score > 80 and errors < 2:
        return "Excellent! Keep going strong!"
    elif score > 50:
        return "Good effort! Let's fix those small mistakes."
    else:
        return "Let’s revise fundamentals and try again. You got this!"

def evolve_persona(current: str, progress: int) -> str:
    """Suggests adjusting persona based on learning progress."""
    if current == "Cheerleader" and progress > 70:
        return "Evolving to 'Chill Peer' for a bit more independence!"
    elif current == "Chill Peer" and progress > 85:
        return "Upgrading to 'Strict Mentor' to challenge your skills!"
    elif progress < 40:
        return "Switching to 'Cheerleader' to rebuild confidence!"
    return f"Sticking with '{current}' for now."

# ========== TOOL WRAPPERS ==========

tools = [
    Tool.from_function(
        func=select_persona,
        name="select_persona",
        description="Select a learning persona: Strict Mentor, Chill Peer, or Cheerleader."
    ),
    Tool.from_function(
        func=interactive_coding,
        name="interactive_coding",
        description="Solve a code task based on the selected persona."
    ),
    Tool.from_function(
        func=feedback,
        name="feedback",
        description="Give performance feedback using score, errors, and time spent."
    ),
    Tool.from_function(
        func=evolve_persona,
        name="evolve_persona",
        description="Suggest next persona based on current one and user progress."
    ),
]

# ========== AGENT + MEMORY ==========

prompt = ChatPromptTemplate.from_messages([
    ("system", "You are a helpful AI Pair Coder with adaptive teaching styles."),
    MessagesPlaceholder(variable_name="chat_history"),
    ("human", "{input}"),
    MessagesPlaceholder(variable_name="agent_scratchpad"),
])

memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)
agent = create_tool_calling_agent(llm=llm, tools=tools, prompt=prompt)
executor = AgentExecutor(agent=agent, tools=tools, memory=memory, verbose=False)

# ========== AGENT WRAPPER FUNCTION ==========

def chat_with_agent(user_input):
    try:
        result = executor.invoke({"input": user_input})
        return result["output"]
    except Exception as e:
        return f"❌ Error: {str(e)}"

# ========== GRADIO UI ==========

with gr.Blocks(theme=gr.themes.Soft()) as demo:
    gr.Markdown("## 🤖 AI Pair Coder with Learning Personas")
    gr.Markdown("Select a persona, solve tasks, get feedback, and grow.")

    chatbot = gr.Chatbot()
    msg = gr.Textbox(placeholder="Type something like: select_persona with preference Cheerleader")
    clear = gr.Button("Clear")

    def respond(message, history):
        reply = chat_with_agent(message)
        history.append((message, reply))
        return history, ""

    msg.submit(respond, [msg, chatbot], [chatbot, msg])
    clear.click(lambda: [], None, chatbot)

demo.launch(share=True)  # ✅ Shows gradio.live URL