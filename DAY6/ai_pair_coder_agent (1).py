# -*- coding: utf-8 -*-
"""AI Pair Coder agent.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gaawuTtCuEzOz6yNtZfE0AsTF0WNO_zY
"""

# ✅ AI Pair Coder (LangChain + Gemini 1.5 Flash + Gradio UI)
# Google Colab-ready script

!pip install -q langchain langchain_google_genai gradio google-generativeai

from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.agents import create_tool_calling_agent, AgentExecutor
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.messages import HumanMessage, AIMessage
from langchain_core.tools import tool
import gradio as gr
import random

# ✅ SETUP Gemini 1.5 Flash (make sure you have a valid API key set)
import os
os.environ["GOOGLE_API_KEY"] = "AIzaSyCSPF7G0XWuW14B6Pvz6oI4mCo2jQU3c48"  # replace with your actual key
llm = ChatGoogleGenerativeAI(model="models/gemini-1.5-flash", temperature=0.4)

# ✅ Memory state to simulate XP and personality
state = {"xp": 0.0, "last_answer": ""}

def evolve_personality(xp: float) -> str:
    if xp < 0.3:
        return "Cheerleader"
    elif xp < 0.6:
        return "Chill Peer"
    else:
        return "Strict Mentor"

PERSONALITY_MAP = {
    "Cheerleader": "You're positive and encouraging, no matter the question.",
    "Chill Peer": "You're relaxed, give smart hints, and share some jokes.",
    "Strict Mentor": "You're serious, demanding, and expect top performance."
}

# ✅ TOOL 1: Quiz Generator
@tool
def quiz_tool() -> str:
    """Send one quiz question with options."""
    questions = [
        {
            "question": "Which of these is NOT a Python datatype?",
            "answer": "C",
            "options": ["A. list", "B. dict", "C. graph", "D. tuple"]
        },
        {
            "question": "Which keyword handles exceptions?",
            "answer": "A",
            "options": ["A. try/except", "B. finally", "C. loop", "D. handle"]
        },
        {
            "question": "What does type([]) return?",
            "answer": "A",
            "options": ["A. <class 'list'>", "B. list", "C. list()", "D. array"]
        }
    ]
    q = random.choice(questions)
    state["last_answer"] = q["answer"]
    return f"\U0001f9e0 Quiz:\n{q['question']}\n" + "\n".join(q["options"]) + "\n\nReply using: Answer: A/B/C/D"

# ✅ TOOL 2: Answer Quiz (improved with XP decrease on wrong answer)
@tool
def answer_quiz(answer: str) -> str:
    """Accepts answer and updates XP."""
    correct = state.get("last_answer", "")
    if not correct:
        return "⚠️ No quiz was asked. Use 'quiz_tool' to get a quiz first."

    if answer.strip().upper() == correct:
        state["xp"] += 0.3
        state["xp"] = min(state["xp"], 1.0)
        return f"✅ Correct! XP: {int(state['xp'] * 100)}%. Personality now: {evolve_personality(state['xp'])}."
    else:
        state["xp"] -= 0.2
        state["xp"] = max(state["xp"], 0.0)
        return f"❌ Incorrect. Correct answer: {correct}. XP: {int(state['xp'] * 100)}%. Personality now: {evolve_personality(state['xp'])}."

# ✅ TOOL 3: Personality Tool
@tool
def personality_tool(input: str) -> str:
    """Respond using current XP-based personality."""
    persona = evolve_personality(state["xp"])
    tone = PERSONALITY_MAP[persona]
    return f"[{persona} Mode]\n{tone}\nNow respond to this: {input}"

# ✅ TOOL 4: Code Review
@tool
def code_review_tool(code_question: str) -> str:
    """Review code in XP-based style."""
    persona = evolve_personality(state["xp"])
    return f"You are acting like a GitHub reviewer in {persona} mode. Review this:\n\n{code_question}"

# ✅ PROMPT + AGENT SETUP
prompt = ChatPromptTemplate.from_messages([
    ("system", "You are a coding pair partner who adapts your style."),
    MessagesPlaceholder(variable_name="chat_history"),
    ("human", "{input}"),
    MessagesPlaceholder(variable_name="agent_scratchpad")
])

agent = create_tool_calling_agent(
    llm=llm,
    tools=[quiz_tool, answer_quiz, personality_tool, code_review_tool],
    prompt=prompt
)

agent_executor = AgentExecutor(
    agent=agent,
    tools=[quiz_tool, answer_quiz, personality_tool, code_review_tool],
    verbose=True
)

# ✅ CHAT MEMORY
chat_history = []

def handle_interaction(user_input):
    chat_history.append(HumanMessage(content=user_input))
    response = agent_executor.invoke({
        "input": user_input,
        "chat_history": chat_history
    })
    chat_history.append(AIMessage(content=response["output"]))

    new_xp_display = f"### \U0001f9e0 XP: {int(state['xp']*100)}% | Personality: {evolve_personality(state['xp'])}"
    return response["output"], new_xp_display

# ✅ GRADIO UI (with dynamic XP/personality display)
with gr.Blocks() as demo:
    xp_text = gr.Markdown(f"### \U0001f9e0 XP: {int(state['xp']*100)}% | Personality: {evolve_personality(state['xp'])}")
    input_box = gr.Textbox(label="Ask coding help / Request quiz / Review code")
    output_box = gr.Textbox(label="Agent Response")
    send_btn = gr.Button("Send")

    send_btn.click(fn=handle_interaction, inputs=input_box, outputs=[output_box, xp_text])

# ✅ Launch
demo.launch(debug=True, share=True)