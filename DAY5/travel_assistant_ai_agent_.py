# -*- coding: utf-8 -*-
"""Travel Assistant AI agent .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wjZ2KH5-1nzycW8ryqZhTLmLuNXS923g
"""

# ✅ Step 1: Install required packages
!pip install --quiet langchain langchain-google-genai tavily-python google-generativeai
!pip uninstall -y google-ai-generativelanguage
!pip install --quiet google-ai-generativelanguage==0.6.15

!pip install -U langchain --quiet

!pip install --upgrade langchain --quiet

# ✅ Step 2: Imports & API Key setup
import os
import requests
import google.generativeai as genai
from tavily import TavilyClient

# ✅ Add your keys here
os.environ["GOOGLE_API_KEY"] = "AIzaSyCmZoB_KgBCGKo_zq74lat2iQqeDEhujbs"
os.environ["TAVILY_API_KEY"] = "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"
WEATHER_API_KEY = "b77cfd80e91842f1a60112223251406"

# ✅ Configure Gemini
import google.generativeai as genai

# ✅ Use your Gemini API key directly here
genai.configure(api_key="AIzaSyCmZoB_KgBCGKo_zq74lat2iQqeDEhujbs")

# ✅ Step 3: LangChain - Set up Gemini LLM
from langchain_google_genai import ChatGoogleGenerativeAI

llm = ChatGoogleGenerativeAI(model="gemini-1.5-flash", temperature=0.3)

# ✅ Step 4: Define Tools using @tool
from langchain.tools import tool

@tool
def get_weather(city: str) -> str:
    """Fetch current weather for a city using WeatherAPI."""
    url = f"http://api.weatherapi.com/v1/current.json?key={WEATHER_API_KEY}&q={city}"
    res = requests.get(url)
    if res.status_code != 200:
        return "Weather data unavailable."
    data = res.json()
    temp = data["current"]["temp_c"]
    cond = data["current"]["condition"]["text"]
    return f"{city} is currently {temp}°C with {cond.lower()}."

@tool
def search_attractions(city: str) -> str:
    """Search for top tourist attractions in a city using Tavily."""
    client = TavilyClient()
    results = client.search(query=f"top tourist attractions in {city}", max_results=5)
    return "\n".join([f"- {r['title']} ({r['url']})" for r in results["results"]])

from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.agents import create_tool_calling_agent, AgentExecutor

# Gemini-friendly tool-call prompt
prompt = ChatPromptTemplate.from_messages([
    ("system", "You are a travel assistant. Always use the tools to answer questions."),
    ("user", "{input}"),
    MessagesPlaceholder(variable_name="agent_scratchpad")
])

# Tools list
tools = [get_weather, search_attractions]

# Agent setup — no OpenAI parsers!
agent = create_tool_calling_agent(
    llm=llm,
    tools=tools,
    prompt=prompt,
)

agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)

response = agent_executor.invoke({"input": "Plan a trip to bengaluru with weather and attractions"})
print(response["output"])

